import{_ as a,o as r,c as e,a as s}from"./app-dwKQwfL2.js";const n="/assets/transformer-architecture-6OotzNNu.png",o="/assets/transformer-model-architecture-TFm8283L.png",t={},c=s('<h1 id="transformer" tabindex="-1"><a class="header-anchor" href="#transformer"><span>Transformer</span></a></h1><h2 id="前言" tabindex="-1"><a class="header-anchor" href="#前言"><span>前言</span></a></h2><h2 id="_1-什么是transformer" tabindex="-1"><a class="header-anchor" href="#_1-什么是transformer"><span>1. 什么是Transformer</span></a></h2><p>Transformer是一种基于注意力机制的深度学习模型，由Vaswani等人于2017年提出。它在自然语言处理领域取得了巨大成功，如BERT、GPT等模型都是基于Transformer架构。Transformer模型的核心是自注意力机制，它能够在不同位置的单词之间建立联系，从而更好地捕捉句子中的长距离依赖关系。</p><h2 id="_2-transformer的结构" tabindex="-1"><a class="header-anchor" href="#_2-transformer的结构"><span>2. Transformer的结构</span></a></h2><h2 id="整体结构如下" tabindex="-1"><a class="header-anchor" href="#整体结构如下"><span>整体结构如下</span></a></h2><p><img src="'+n+'" alt=""></p><blockquote><p>由多层编码器和解码器组成，编码器和解码器均由多头自注意力机制和前馈神经网络组成。</p></blockquote><h2 id="单层编码器和解码器的结构如下" tabindex="-1"><a class="header-anchor" href="#单层编码器和解码器的结构如下"><span>单层编码器和解码器的结构如下</span></a></h2><p><img src="'+o+'" alt="transformer-model-architecture.png"></p><blockquote><p>由左侧的编码器和右侧的解码器组成，每个编码器和解码器均由多头自注意力机制和前馈神经网络组成。</p></blockquote><h3 id="编码器" tabindex="-1"><a class="header-anchor" href="#编码器"><span>编码器</span></a></h3>',12),h=[c];function p(f,d){return r(),e("div",null,h)}const m=a(t,[["render",p],["__file","Transformer.html.vue"]]);export{m as default};
