import{_ as t,o as d,c as a,a as n}from"./app-018gsj_b.js";const s={},r=n('<h1 id="微调介绍" tabindex="-1"><a class="header-anchor" href="#微调介绍"><span>微调介绍</span></a></h1><blockquote><p>微调是深度学习中迁移学习的一种形式。它采用预训练模型，且该模型已在大型数据集上训练过，用于自然语言处理或图像识别等通用任务,对其部分参数进行微调，使其在某一专业领域具有更好的效果,而无需从头开始训练。</p></blockquote><h2 id="应用场景" tabindex="-1"><a class="header-anchor" href="#应用场景"><span>应用场景</span></a></h2><h3 id="适用场景" tabindex="-1"><a class="header-anchor" href="#适用场景"><span>适用场景</span></a></h3><ul><li><strong>任务特定性：</strong> 当任务具有明确的目标和结构时，如情感分析、文本分类、命名实体识别等，微调能够让预训练模型更好地适应这些特定任务。</li><li><strong>有限的标注数据：</strong> 即使只有少量的标注数据，微调也能通过调整预训练模型的参数来提升模型在特定任务上的性能。</li><li><strong>需求高准确率：</strong> 对于需要高度准确性的任务，微调可以通过细致调整模型以适应特定数据集的特点，从而提高准确率。</li><li><strong>计算资源限制：</strong> 相对于从头训练模型，微调需要的计算资源较少，适合计算资源受限的情况。</li></ul><h3 id="不适用场景" tabindex="-1"><a class="header-anchor" href="#不适用场景"><span>不适用场景</span></a></h3><ul><li><strong>时序数据高频更新的场景：</strong> 当任务的数据分布和特点经常变化时，微调可能无法适应这种变化。</li><li><strong>大规模数据集：</strong> 当任务的数据集规模非常大时，微调可能无法充分利用这些数据，从而无法发挥其优势。</li><li><strong>任务特定性不强：</strong> 当任务的目标和结构不明确时，微调可能无法有效提升模型性能。</li><li><strong>需求高泛化性：</strong> 对于需要高泛化性的任务，微调可能无法满足这一需求。</li><li><strong>场景数据过少：</strong> 当任务的数据集规模非常小时，微调可能无法充分利用这些数据，从而无法发挥其优势。</li></ul><h2 id="为什么要使用微调" tabindex="-1"><a class="header-anchor" href="#为什么要使用微调"><span>为什么要使用微调？</span></a></h2><ul><li><strong>资源利用最大化：</strong> 通过微调，可以充分利用现有的预训练模型和其在广泛数据上学到的知识，避免了重复进行昂贵的预训练过程，从而实现资源的高效利用。</li><li><strong>计算效率：</strong> 微调一个预训练模型通常需要更少的计算资源和时间。这是因为预训练模型已经学习了大量的通用知识，只需要较小的调整即可适应新任务。</li><li><strong>性能优化：</strong> 微调可以进一步优化模型的性能，提高其在特定任务上的准确性、效率和鲁棒性。</li><li><strong>泛化能力：</strong> 即使是小规模的数据集，通过微调，模型也能学习到足够的任务特定知识，从而在新样本上表现良好。</li></ul><h2 id="基础知识" tabindex="-1"><a class="header-anchor" href="#基础知识"><span>基础知识</span></a></h2><h3 id="核心库组件" tabindex="-1"><a class="header-anchor" href="#核心库组件"><span>核心库组件</span></a></h3><ul><li><p><strong>Transformers：</strong> 核心库、模型加载、模型训练、模型评估、模型部署</p></li><li><p><strong>Tokenizers：</strong> 分词器、词向量、词嵌入、词表</p></li><li><p><strong>Datasets：</strong> 模型加载、模型训练、模型评估、模型部署</p></li><li><p><strong>Evaluate：</strong> 评估函数、提供各种评估指标的计算函数</p></li><li><p><strong>PFFT：</strong> 高效模型微调库，支持多种微调方法</p></li><li><p><strong>Accelerate：</strong> 分布式训练、混合精度训练、多卡训练、多机训练、提供了分布式模型训练推理解决方案</p></li><li><p><strong>PyTorch：</strong> 模型加载、模型训练、模型评估、模型部署</p></li><li><p><strong>TensorFlow：</strong> 模型加载、模型训练、模型评估、模型部署</p></li><li><p><strong>Keras：</strong> 模型加载、模型训练、模型评估、模型部署</p></li><li><p><strong>NLP：</strong> 文本分类、情感分析、命名实体识别、文本生成、机器翻译</p></li><li><p><strong>CV：</strong> 图像分类、目标检测、图像生成、图像分割</p></li><li><p><strong>MLOps：</strong> 模型训练、模型评估、模型部署、模型监控</p></li><li><p><strong>AutoML：</strong> 模型搜索、超参数优化、模型选择、模型融合</p></li></ul><h3 id="核心方法" tabindex="-1"><a class="header-anchor" href="#核心方法"><span>核心方法</span></a></h3><ul><li><strong>模型评估：</strong> 准确率、精确率、召回率、F1值、AUC值、混淆矩阵</li><li><strong>模型部署：</strong> 本地部署、云端部署、边缘部署、移动端部署</li><li><strong>模型监控：</strong> 模型性能、模型健康、模型可解释性、模型鲁棒性</li><li><strong>模型融合：</strong> 模型集成、模型融合、模型蒸馏、模型剪枝</li><li><strong>模型搜索：</strong> 超参数搜索、架构搜索、模型搜索、模型选择</li><li><strong>超参数优化：</strong> 网格搜索、随机搜索、贝叶斯优化、进化算法</li><li><strong>模型选择：</strong> 模型评估、模型选择、模型融合、模型蒸馏</li><li><strong>模型融合：</strong> 模型集成、模型融合、模型蒸馏、模型剪枝</li></ul><h2 id="微调的步骤" tabindex="-1"><a class="header-anchor" href="#微调的步骤"><span>微调的步骤</span></a></h2><h3 id="_1-选择预训练模型" tabindex="-1"><a class="header-anchor" href="#_1-选择预训练模型"><span>1. 选择预训练模型</span></a></h3><p>选择一个在大规模数据集上训练过的预训练模型，如BERT、GPT、ResNet等。选择的预训练模型应该与任务的特点相匹配，如BERT适用于文本任务，ResNet适用于图像任务。</p><h3 id="_2-准备数据集" tabindex="-1"><a class="header-anchor" href="#_2-准备数据集"><span>2. 准备数据集</span></a></h3><p>定义数据加载器</p><h3 id="_3-构建模型" tabindex="-1"><a class="header-anchor" href="#_3-构建模型"><span>3. 构建模型</span></a></h3><h3 id="_4-定义损失函数" tabindex="-1"><a class="header-anchor" href="#_4-定义损失函数"><span>4. 定义损失函数</span></a></h3><h3 id="_5-定义优化器" tabindex="-1"><a class="header-anchor" href="#_5-定义优化器"><span>5. 定义优化器</span></a></h3><h3 id="_6-训练模型" tabindex="-1"><a class="header-anchor" href="#_6-训练模型"><span>6. 训练模型</span></a></h3><h3 id="_7-评估模型" tabindex="-1"><a class="header-anchor" href="#_7-评估模型"><span>7. 评估模型</span></a></h3><h3 id="_8-部署模型" tabindex="-1"><a class="header-anchor" href="#_8-部署模型"><span>8. 部署模型</span></a></h3><h2 id="微调方法" tabindex="-1"><a class="header-anchor" href="#微调方法"><span>微调方法</span></a></h2><table><thead><tr><th>微调方法</th><th>参数调整范围</th><th>资源效率</th><th>适用性</th><th>潜在性能影响</th><th>特点</th><th>明确优点</th><th>缺点</th><th>注意事项</th></tr></thead><tbody><tr><td>Prompt Tuning</td><td>仅限输入提示参数</td><td>高</td><td>NLP任务，如分类、问答、文本生成，尤其适合大型语言模型</td><td>可能需要大量样本</td><td>无需调整原始模型参数</td><td>- 无需修改模型参数，减小模型尺寸</td><td>- 需要大量样本用于学习提示</td><td>- 提示的设计对性能影响重大，需要谨慎选择</td></tr><tr><td>P-Tuning</td><td>任务特定的提示参数</td><td>中到高</td><td>NLP任务，包括但不限于实体识别、情感分析、文本摘要</td><td>取决于训练样本量</td><td>引入可学习的连续嵌入作为提示</td><td>- 相对于全参数微调更高效</td><td>- 样本不足时可能效果有限</td><td>- 提示设计和样本多样性对性能有影响</td></tr><tr><td>Prefix-Tuning</td><td>解码器前缀参数</td><td>中</td><td>序列生成任务，如文本生成、机器翻译、代码生成</td><td>可能稍逊于全参数微调</td><td>在解码步骤前添加可学习的前缀</td><td>- 节省计算资源，适用于序列生成任务</td><td>- 生成质量可能不如全参数微调</td><td>- 前缀的设计需要考虑生成任务的特点</td></tr><tr><td>LoRA</td><td>低秩矩阵参数</td><td>高</td><td>广泛应用于NLP和视觉任务，如图像分类、对象检测、语言理解和生成</td><td>微小到中等的性能损失</td><td>通过添加低秩矩阵调整权重</td><td>- 高效降低模型参数数量，保持性能</td><td>- 需要仔细的超参数调整</td><td>- 低秩矩阵的维度和超参数的选择非常重要</td></tr><tr><td>QLoRA</td><td>量化的低秩矩阵参数</td><td>非常高</td><td>资源受限环境，如移动设备和嵌入式系统，适用于NLP和视觉任务</td><td>可能有精度损失</td><td>引入量化技术进一步减少参数</td><td>- 极大地减小模型大小和计算需求</td><td>- 量化可能导致精度损失，需要权衡</td><td>- 量化方法的选择和位宽需要小心考虑</td></tr><tr><td>AdaLoRA</td><td>动态调整的低秩矩阵参数</td><td>中到高</td><td>多任务学习、持续学习、场景适应，适用于需要模型动态适应不同任务的场景</td><td>取决于调整策略</td><td>动态调整低秩矩阵的更新</td><td>- 适应不同任务的动态性能调整</td><td>- 需要精心设计调整策略</td><td>- 调整策略的设计和样本多样性对性能有影响</td></tr></tbody></table><h2 id="微调的注意事项" tabindex="-1"><a class="header-anchor" href="#微调的注意事项"><span>微调的注意事项</span></a></h2><ul><li>RLHF (Reinforcement Learning from Human Feedback)</li></ul>',29),i=[r];function o(e,h){return d(),a("div",null,i)}const p=t(s,[["render",o],["__file","introduction.html.vue"]]);export{p as default};
